## one-city编程大赛(文本分类)
[赛事地址](https://www.dcjingsai.com/v2/cmptDetail.html?id=457)

## 赛题分析
本赛题为一个典型的文本分类任务,总共20类别,类别并不均衡,同时数据很脏,需要自己合理的构造训练数据.
我的解决思路:
- 初赛：只用标题数据,bert直接分类
- 复赛：由于去掉了一半的标题,所以需要考虑使用表格内容.由于表格的大小,内容丰富度十分不一致，
因此很难对数据进行合理的处理.我一开始读入了每一个表格的前10行，利用正则表达式
提取出其中的中文.然后jieba分词,进行词频统计,将频率最高的20个词语提取出来,接在标题文本的后面.然后再将前10行的内容一并接在后面。这样便构成了训练集.

**分类模型**:
- **bert：**（基于腾讯开源的的UER-py框架,哈工大开源的wwm预训练中文模型，代码后面整理完毕开源）:这也是初赛使用的以及复赛前两天尝试的模型,猜测可能由于复赛制作的训练集长度变化很大，而且加上内容和关键字信息后缺乏语义信息,
反而使得bert无法学习到关键模式.线上只有80出头.一度想要弃赛,

- **FastText：**
最后两次机会决定试一试fastText，结果随便一训练,线上90+了.事后的线下验证也差不多在90~91左右.同时听取了大佬的建议,将所有内容数据都读入，同时将初赛的8k条数据也加入到了训练集,
训练了一个五折的fastText，线下验证acc在93+。
看了下结果,比线上90的那个要好很多,本想着再改进改进,留到最后一刻上一波分想着冲一个耳机应该没问题了,结果八点的时候看群里面讲比赛已经截止了。心态顿时爆炸！！遂开源.
