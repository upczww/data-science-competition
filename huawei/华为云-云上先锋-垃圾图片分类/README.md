## [云上先锋--垃圾图片分类](https://competition.huaweicloud.com/information/1000041335/ranking?track=112)
历时一个月,最终取得了本次比赛的**冠军**,这里分享一下自己的方案

关于源码:比较trick的一些东西暂不开源,[戳这里](https://github.com/DLLXW/data-science-competition/tree/main/%E5%8D%8E%E4%B8%BA/Huawei-cloud-%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB)，这是比赛刚开始几天我开源的一个线上92的baseline，是使用的resnet50作为backbone,其实将resnet50改为swsl就可以轻易上分了
## 比赛介绍
本赛题采用深圳市垃圾分类标准，赛题任务是对垃圾图片进行分类，即首先识别出垃圾图片中物品的类别（比如易拉罐、果皮等），然后查询垃圾分类规则，输出该垃圾图片中物品属于可回收物、厨余垃圾、有害垃圾和其他垃圾中的哪一种。

图片总数:19w+

类别数:43

数据分布:总体而言,较为均衡,只有少数类别的样本数较少,而且线下验证表明这些少数类别的分类效果并不算差

## 模型
我所采取的模型是:swsl_resnext101_32x8d,选该模型的理由:

1.该模型对输入图片尺寸要求较小,那么意味着对硬件的要求较低,efficient系列的模型按理说会比该模型好,但没有硬件真训练不了。

2.往届的垃圾图片分类大赛也是该模型霸占了排行榜，泛化能力较高。

其实主要还是因为训练资源要求不高,224的输入都能获得很好的效果,这样一来，做消融对比实验的周期大大缩短,更有利于后期的优化提升，eff系列的模型,即使是b4，也相当耗时。

## 数据增强
**常规增强**

这里就要好好的说一下了,对于本问题而言,不要加太多花里胡哨的数据增强就是最好的增强，本身图片质量就很好，而且目标占比很大，目标具有一些位置特点(对于一些譬如大角度旋转，垂直翻转之类的操作,反而会给数据集带来不合理性)，所以对于数据增强，我的建议是一个水平flip即可，同时可以配合下高斯噪声，颜色变换等，但变化尺度不宜过大。

**一些很magic的数据增强手段：**

**mixup,cutmix,Fmix** 这三个比较trick的增强手段,在很多的图像分类任务上都有明显的涨点，对于本次的垃圾分类任务，在线上96.20以下的时候，这些增强手段还有显著的提升效果(线上/线下都有提升), 但是其实当我到达96.5时，这些增强手段就没有那么显著的提升效果。但是线下涨点是很明显的,往往可以涨一个百的线下，但线上效果有限。

**外部数据**

对于外部数据而言，由于很难找到和官方数据集的分布相同的外部数据集，所以就算引入了外部数据，可能会导致训练集和测试集的差异变得更大，导致模型表现不佳，所以此问题我并未使用外部数据。

## 训练尺度和训练策略
训练尺度: 其实对于尺度问题而言,并不是越大表现越好,swsl模型默认的244尺度是不行的,288的尺度线上大概可以到955+,最好的尺度范围在320~416之间。而且预测的尺度需要比训练使用的尺度略微大一些，也即小尺度训练，大尺度预测。

**一些涨点策略:**

**FIX训练策略:** 先用一个较小的尺度训练模型,再对该模型用稍大尺度进行一个finetune,此时可以选择冻结部分层的参数，只训练一部分，测试时候使用大尺度。

**带warm-up的cosine学习率调整策略:** 学习率调整策略需要当做重点来阐述，很多选手可能随便的设置初始学习率和学习率scheduler策略(甚至不使用scheduler)，这是很多人的baseline效果不好的原因，学习率的初始值和调节策略十分的重要。这里给出一条原则:可以先使用stepLR或者指数LR来搭建初始的pipeline，根据自己的线上/下表现，确定模型达到最优的step（或者epoch），然后再重新设计自己的scheduler。cosine学习率用好了是一个涨点神器，用不好肯定会反向优化。

**对于选择adam还是sgd的问题??** 都2021年了，还有CVer问这种问题吗? CV领域用SGD,自然语言处理领域用Adam(AdamW已经是NLPer的标配了)，至于原因:很多大佬都探讨过了，大致是这样: 1.sgd的数学机制已经搞得很透彻了，比起 adam, sgd更加倾向于找到flat-minima, 泛化能力会更好。2. Adam适合于那种比较极端的loss landscape,譬如NLP中的大多数任务,Loss Landscape就会有很多"悬崖峭壁",Adam就适合干这事。

**swa**: 由于官方禁止了推理时候的多模型融合,但是还有一种模型融合方式，是将同一个模型的不同训练阶段的权重进行平均成为一个新模型。最终还是单模型，该方法可以使得模型具有更强的泛化能力。

**bad case**:线下验证是可以画出混淆矩阵的，可以清楚的看到某些类别是模型预测得不够好的，针对这些类别，以及容易混淆的类别，可以做一些针对性的数据增强策略，我最终是选了11个类别，训练的时候只针对这11个类别使用诸如cut-mix之类的数据增强手段。

**另附:**
[top7的选手开源的方案](https://blog.csdn.net/qq_39752470/article/details/109704202?utm_source=app)
